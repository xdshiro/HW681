{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **2 Classic Exercises in VC Dimension (Ed Tam)**\n",
    "**2.1 VC dimension of a step functions**\n",
    "\n",
    "VC=1\n",
    "\n",
    "For 2 points $x_1$ and $x2$, where $x_2>x_1$, we cannot classify $x_2$ as 1 and $x_1$ as 0,\n",
    " since if $t>x_2$, then\n",
    "everything less than t is 1. $x_1<x_2<t$ => $x_1$ is also classified as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.2 VC dimension of interval**\n",
    "\n",
    "VC=2\n",
    "\n",
    "2 points $x_1<x_2$ can be classified easily: 00 if $t_1>x_2$, 01 if x_1<t_1<x_2<t_2,\n",
    " 10 of $t_1<x_1<t_2<x_2$, 11 if $t_1<x_1<x_2<t_2$.\n",
    "\n",
    " 3 points $x_1<x_2<x_3$ cannot be classified as 101, because if $t_1<x_1<x_3<t_2$ then $x_2$ also\n",
    " has to be 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.3 VC dimension of hyperplanes through origin**\n",
    "\n",
    "VC=d, where d is the dimension of the space.\n",
    "\n",
    "The lower bound can be easily seen if we use the the classifier $b^T=\\sum_{i=1}^dy_ix_i$ used on\n",
    "points ${x_1,...,x_d}$, where $x_{ij}=\\delta_{ij}$.\n",
    "In that case\n",
    "\n",
    "$$f(x_j)=sign(b^Tx_j)=sign(\\sum_{i=1}^dy_ix_ix_j)=sign(y_j)=y_j,$$\n",
    "\n",
    "and thus, all the points are classified correctly.\n",
    "\n",
    "for the upper bound lets consider 1D case. there is position for $x_2>x_1$ which we can classify as 01 and 10\n",
    "at the same time. if both dots are greater or less than 0, they can only have the same label. if\n",
    "$x_2>0>x_1$, then we cannot have the same label on both both simultaneously.\n",
    "\n",
    "Even thou it is not the strict proof, we can see how adding extra dimension increases the degree of\n",
    "freedom by 1, so each $d+1$ give us 1 extra point we can classify correctly.\n",
    "It can be checked in the case of 2D. We cannot classify 3 points in all the possible ways. If we position them\n",
    "in the way they all have  the same label, there is not way to way to do it in all the possible combinations\n",
    "001, 010, 100."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.4 VC dimension of binary decision trees**\n",
    "\n",
    "1) VC=$l$, for all binary decision trees with l leaves.\n",
    "\n",
    "For the lower bound we can distribute every point to it's own leave by choosing the correct\n",
    " $x_i=\\{x_{i1}, x_{i2}...x_{il}\\}$ according to each leaf and label each leaf as any $y_i$ we need.\n",
    "\n",
    " For example, for the tree of height 3 with 4 leaves we can select 4 points: 00, 01, 10, 11. First split\n",
    " is based on the 1st feature, 2nd split is based on 2nd feature. so all the points are in their own leaves\n",
    " and we can give them any labels from the set {00, 01, 10, 11}.\n",
    "\n",
    " The upper bound can be understood from a simpler example of a tree with 2 leaves. Let's say we have 3 points\n",
    " {00, 10, 11}. If the split is made based on the 1st feature, then 2nd and 3rd points will\n",
    " be in the same leaf, if the split is made based on the 2nd feature - 1st and 2nd points are in the same leaf.\n",
    " In that case there is no possible split that classify 1st point as 1, 2nd point as 0, and 3rd point as 1,\n",
    " because we cannot place 1st and 3rd points into the same leaf.\n",
    "For the points {00, 10, 01} we can use the same logic. So we cannot shatter 3 points.\n",
    "\n",
    "2) VC=d+1\n",
    "\n",
    "The number of leaves l is the number of splits + 1, so l=d+1. So they same explanation stands."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.5 VC dimension upper bounds for a finite class**\n",
    "\n",
    "Let $F$ be a finite hypothesis class for binary classification.\n",
    "\n",
    "Let's say $VC(F)=d$, then for these $d$ points we have $2^d$ different combinations of labels,\n",
    "because they all have to be classified in all possible way (the number of subsets of d points\n",
    "is equal to $2^d$). Thus,\n",
    "we have at least $2^d$ functions that can give us this labels, so $|C|\\ge 2^d$. From that we can\n",
    "write $\\log_2|C|\\ge d=VC(F)$ or $VC\\le log_2|C|$.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}