{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgTNTrbqDQTX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchvision import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Do Not Touch This Cell\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6a29nw3JDYwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Do Not Touch This Cell\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = Net().to(device)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "if device =='cuda':\n",
        "    print(\"Train on GPU...\")\n",
        "else:\n",
        "    print(\"Train on CPU...\")"
      ],
      "metadata": {
        "id": "bYVvBsNKDjdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Do Not Touch This Cell\n",
        "max_epochs = 50\n",
        "\n",
        "random_seed = 671\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "id": "Bu618_bdDyaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose(\n",
        "     [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "     [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "##TODO: Split the set into 80% train, 20% validation (there are 50K total images)\n",
        "train_num = \n",
        "val_num = \n",
        "train_set, val_set = random_split(dataset, [train_num, val_num])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "lvBlqSLwD1bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list, acc_list = [], []\n",
        "loss_list_val, acc_list_val = [], []\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    #TODO: set the net to train mode:\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        ##TODO: pass the data into the network and store the output\n",
        "\n",
        "        ##TODO: Calculate the cross entropy loss between the output and target \n",
        "  \n",
        "        ##TODO: Perform backpropagation\n",
        "\n",
        "\n",
        "        ##TODO: Get the prediction from the output\n",
        "\n",
        "        ##TODO: Calculate the correct number and add the number to correct\n",
        "\n",
        "        ##TODO: Add the loss to epoch_loss.\n",
        "\n",
        "    ##TODO: calculate the average loss\n",
        "\n",
        "    ##TODO: calculate the average accuracy\n",
        "\n",
        "    ##TODO: append average epoch loss to loss list\n",
        "\n",
        "    ##TODO: append average accuracy to accuracy list\n",
        "\n",
        "    # validation\n",
        "    ##TODO: set the model to eval mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss_val = 0.0\n",
        "        correct_val = 0\n",
        "        for batch_idx, (data, labels) in enumerate(val_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            ##TODO: pass the data into the network and store the output\n",
        "\n",
        "            ##TODO: Calculate the cross entropy loss between the output and target \n",
        "\n",
        "            ##TODO: Get the prediction from the output\n",
        "\n",
        "            ##TODO: Calculate the correct number and add the number to correct_val\n",
        "\n",
        "            ##TODO: Add the loss to loss_val\n",
        "\n",
        "        ##TODO: calculate the average loss of validation\n",
        "\n",
        "        ##TODO: calculate the average accuracy of validation\n",
        "\n",
        "        ##TODO: append average epoch loss to loss list of validation\n",
        "\n",
        "        ##TODO: append average accuracy to accuracy list of validation\n",
        "\n",
        "    print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f' % (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val))"
      ],
      "metadata": {
        "id": "3tTdQ-8lFY57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO: Plot the training losses and validation losses\n"
      ],
      "metadata": {
        "id": "9rnxqivjbaZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO: Plot the training accuracies and validation accuracies\n"
      ],
      "metadata": {
        "id": "9NzRkpMQeoVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "true_labels = []\n",
        "predictions = []\n",
        "correct_test = 0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        ##TODO: pass the data into the network and store the output\n",
        "\n",
        "        ##TODO: Get the prediction from the output\n",
        "\n",
        "        ##TODO: Calculate the correct number and add the number to correct_test\n",
        "\n",
        "        ##TODO: update predictions list and true label list\n",
        "        ##We can directly append the value because here batch_size=1\n",
        "\n",
        "\n",
        "print('Accuracy on the 10000 test images: %.2f %%' % (100 * correct_test / len(test_set)))"
      ],
      "metadata": {
        "id": "zoZp-CnkXlHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO: print the confusion matrix of test set\n",
        "##You can use sklearn.metrics.confusion_matrix\n"
      ],
      "metadata": {
        "id": "UIG4QdQZmxCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}