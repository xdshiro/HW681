{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **2 Topic Modeling with EM (Ed Tam)**\n",
    "\n",
    "**2.1 Derive Log-Likelihood**\n",
    "\n",
    "Let's right the likelihood for this problem:\n",
    "\n",
    "$$L(\\theta)=P(\\bar w=\\bar{q}, \\bar d | \\bar \\alpha, \\bar \\beta)=P(\\bar w=\\bar{q}, \\bar d | \\theta),$$\n",
    "\n",
    "where I used the notation $\\theta = \\bar \\alpha, \\bar \\beta$. Since the probability of a word $w_n$\n",
    " appears in the document $i$ is $p_{ni}$, we can say, that\n",
    "the probability to appear $q(w_n; d_i)$ times is $p_{ni}^q(w_n; d_i)$. In that case, we can write the likelihood as follow:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L(\\theta)=\\prod_{i=1}^M\\prod_{n=1}^N P(w_i=q(w_n; d_i)|\\theta_{i,n})=\\prod_{i=1}^M\\prod_{n=1}^N p_{ni}^{q(w_n; d_i)}=\\\\\n",
    "=\\prod_{i=1}^M\\prod_{n=1}^N (\\sum_{k=1}^K\\beta_{kn}\\alpha_{ik})^{q(w_n; d_i)},\n",
    "\\end{eqnarray}\n",
    "\n",
    "Log-likelihood then\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log L(\\theta)=\\log \\prod_{i=1}^M\\prod_{n=1}^N (\\sum_{k=1}^K\\beta_{kn}\\alpha_{ik})^{q(w_n; d_i)}=\\\\\n",
    "=\\sum_{i=1}^M\\sum_{n=1}^N \\log (\\sum_{k=1}^K\\beta_{kn}\\alpha_{ik})^{q(w_n; d_i)}=\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\log \\sum_{k=1}^K\\beta_{kn}\\alpha_{ik},\n",
    "\\end{eqnarray}\n",
    "\n",
    "So\n",
    "\n",
    "$$\\log L(\\theta)=\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\log \\sum_{k=1}^K\\beta_{kn}\\alpha_{ik}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.2 E Step**\n",
    "\n",
    "Using Bayes rule we can write\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})=\\dfrac{p(w_n|z_k,d_i,\\alpha^{old},\\beta^{old})p(z_k|d_i,\\alpha^{old},\\beta^{old})}{p(w_n|d_i,\\alpha^{old},\\beta^{old})},\n",
    "\\end{eqnarray}\n",
    "\n",
    "Now, since the appearance of the word $w_n$ in the topic $z_k$ is independent of the book $d_i$, we can use\n",
    "\n",
    "$$p(w_n|z_k,d_i,\\alpha^{old},\\beta^{old})=p(w_n|z_k,\\alpha^{old},\\beta^{old})=\\beta^{old}_{nk}.$$\n",
    "\n",
    "Moreover, by definition $p(z_k|d_i,\\alpha^{old},\\beta^{old})=\\alpha^{old}_{ki}$, and\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(w_n|d_i,\\alpha^{old},\\beta^{old})=\\sum_{l=1}^{K}p(w_n|z_l,\\alpha^{old},\\beta^{old})p(z_l|d_i,\\alpha^{old},\\beta^{old})=\\\\\n",
    "=\\sum_{l=1}^{K}\\beta^{old}_{nl}\\alpha^{old}_{li},\n",
    "\\end{eqnarray}\n",
    "\n",
    "and thus\n",
    "\n",
    "$$p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})=\\dfrac{\\beta^{old}_{nk}\\alpha^{old}_{ki}}{\\sum_{l=1}^{K}\\beta^{old}_{nl}\\alpha^{old}_{li}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.3 Find ELBO for M-Step**\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log L(\\theta)=\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\log \\sum_{k=1}^K\\beta_{kn}\\alpha_{ik}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "We can write $\\beta_{kn}\\alpha_{ik}$ as\n",
    "\n",
    "$$\\beta_{kn}\\alpha_{ik}=\\beta_{kn}\\alpha_{ik}\\dfrac{p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})}{p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})}$$\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log L(\\theta)=\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\log \\sum_{k=1}^Kp(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})\\dfrac{\\beta_{kn}\\alpha_{ik}}{p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "So $\\sum_k$ gives us the expectation. In that case we can use Jensen's inequality (since $-\\log$ is convex). Applying\n",
    "the notation $p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})=\\gamma_{ink}$, we have\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\log \\sum_{k=1}^Kp(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})\\dfrac{\\beta_{kn}\\alpha_{ik}}{p(z_k|w_n,d_i,\\alpha^{old},\\beta^{old})}\\ge\\\\\n",
    "\\sum_{i=1}^M\\sum_{n=1}^Nq(w_n; d_i)\\sum_{k=1}^K\\gamma_{ink}\\log \\dfrac{\\beta_{kn}\\alpha_{ik}}{\\gamma_{ink}},\n",
    "\\end{eqnarray}\n",
    "\n",
    "Thus,\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A(\\alpha,\\beta)=\\sum_{i=1}^M\\sum_{n=1}^N\\sum_{k=1}^Kq(w_n; d_i)\\gamma_{ink}\\log \\dfrac{\\beta_{kn}\\alpha_{ik}}{\\gamma_{ink}}.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.4  M-Step**\n",
    "\n",
    "**$\\alpha^{new}$**\n",
    "\n",
    "To find the optimal values of $\\alpha$ and $\\beta$ that maximizes the ELBo with constrains\n",
    " $\\sum_{k=1}^K\\alpha^{new}_{ik}=1$ and $\\sum_{n=1}^N\\beta^{new}_{kn}=1$, let's write\n",
    " the Lagrangian with Lagrangian multipliers:\n",
    "\n",
    " $$L(\\alpha,\\beta)=A(\\alpha,\\beta)+\\gamma_1(1-\\sum_{k=1}^K\\alpha_{ik})+\\gamma_2(1-\\sum_{n=1}^N\\beta_{kn}),$$\n",
    "\n",
    " where the superscript ${new}$ is omitted for brevity.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dfrac{\\partial L(\\alpha,\\beta)}{\\partial \\alpha_{ik}}=\\dfrac{\\partial A(\\alpha,\\beta)}{\\partial \\alpha_{ik}}-\\gamma_1=\\dfrac{\\partial}{\\partial\\alpha_{ik}}\\sum_{i=1}^M\\sum_{n=1}^N\\sum_{k=1}^Kq(w_n; d_i)\\gamma_{ink}\\log \\dfrac{\\beta_{kn}\\alpha_{ik}}{\\gamma_{ink}}-\\gamma_1=\\\\\n",
    "=\\dfrac{\\partial}{\\partial\\alpha_{ik}}\\sum_{n=1}^Nq(w_n; d_i)\\gamma_{ink}\\left(\\log(\\beta_{kn})+\\log(\\alpha_{ik})-\\log(\\gamma_{ink})\\right)-\\gamma_1=\\\\\n",
    "=\\sum_{n=1}^Nq(w_n; d_i)\\gamma_{ink}\\dfrac{1}{\\alpha_{ik}}-\\gamma_1=0.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\\alpha_{ik}=\\dfrac{\\sum_{n=1}^Nq(w_n; d_i)\\gamma_{ink}}{\\gamma_1}.$$\n",
    "\n",
    "Using the constrain $\\sum_{k=1}^K\\alpha_{ik}=1$:\n",
    "\n",
    "\n",
    "$$\\sum_{k=1}^K\\dfrac{\\sum_{n=1}^Nq(w_n; d_i)\\gamma_{ink}}{\\gamma_1}=1,$$\n",
    "\n",
    "$$\\sum_{n=1}^Nq(w_n; d_i)\\sum_{k=1}^K\\gamma_{ink}=\\gamma_1,$$\n",
    "\n",
    "and since $\\gamma_{ink}=p(z_k|w_n,d_i,\\alpha^{old}\\beta^{old})$, its sum is equal to 1 (it's a probability\n",
    "after all), we have\n",
    "\n",
    "$$\\gamma_1=\\sum_{n=1}^Nq(w_n; d_i),$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\alpha_{ik}^{new}=\\dfrac{\\sum_{n=1}^Nq(w_n; d_i)\\gamma_{ink}}{\\sum_{n=1}^Nq(w_n; d_i)},$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\gamma_{ink}=\\dfrac{\\beta^{old}_{nk}\\alpha^{old}_{ki}}{\\sum_{l=1}^{K}\\beta^{old}_{nl}\\alpha^{old}_{li}}.$$\n",
    "\n",
    "\n",
    "Since the substitutions $\\alpha \\leftrightarrow \\beta$ and $i \\leftrightarrow n$ we are\n",
    "getting the same equation, we can skip the derivation of $\\beta_{kn}^{new}$ and write\n",
    "it by analogy with $\\alpha_{ik}^{new}$, since it will be the same:\n",
    "\n",
    "$$\\beta_{kn}=\\dfrac{\\sum_{i=1}^Mq(w_n; d_i)\\gamma_{ink}}{\\gamma_2}.$$\n",
    "\n",
    "To find $\\gamma_2$ let's use the constrain $\\sum_{n=1}^N\\beta_{kn}=1$.\n",
    "\n",
    "$$\\sum_{n=1}^N\\dfrac{\\sum_{i=1}^Mq(w_n; d_i)\\gamma_{ink}}{\\gamma_2}=1,$$\n",
    "\n",
    "$$\\sum_{n=1}^N\\sum_{i=1}^Mq(w_n; d_i)\\gamma_{ink}=\\gamma_2,$$\n",
    "\n",
    "Since I don't see how else I can simplify this equation, the final expression for\n",
    "$\\beta_{kn}^{new}$ is\n",
    "\n",
    "$$\\beta_{kn}=\\dfrac{\\sum_{i=1}^Mq(w_n; d_i)\\gamma_{ink}}{\\sum_{n=1}^N\\sum_{i=1}^Mq(w_n; d_i)\\gamma_{ink}}.$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}